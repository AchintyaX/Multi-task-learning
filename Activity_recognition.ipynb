{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np \n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pylab as plt \n",
    "import random\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.compat.v1.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "my_init = initializers.glorot_uniform(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_raw_data(data_folder)\n",
    "X, Y, Y_std, Y_soc, Y_fourier = prepare_x_y(X, Y)\n",
    "X_train, X_test, Y_train, Y_test, Y_train_std, Y_test_std, \\\n",
    "                     Y_train_soc, Y_test_soc, Y_train_fourier, Y_test_fourier = prepare_train_test(X, \n",
    "                                                                                                   Y, \n",
    "                                                                                                   Y_std, \n",
    "                                                                                                   Y_soc, \n",
    "                                                                                                   Y_fourier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achintya/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.01      0.02      0.02       102\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.80      0.26      0.39        31\n",
      "           4       0.00      0.00      0.00        42\n",
      "           5       0.37      0.16      0.22       100\n",
      "           6       0.00      0.00      0.00        20\n",
      "           7       0.00      0.00      0.00         5\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.23      0.62      0.34       101\n",
      "          10       0.00      0.00      0.00        20\n",
      "          11       0.00      0.00      0.00        28\n",
      "          12       0.24      0.64      0.34       100\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.22      0.14      0.17       100\n",
      "          15       0.00      0.00      0.00        20\n",
      "          16       0.24      0.20      0.22       102\n",
      "          17       0.00      0.00      0.00        20\n",
      "          18       0.00      0.00      0.00        13\n",
      "          19       0.05      0.04      0.05       100\n",
      "          20       0.40      0.10      0.16        20\n",
      "\n",
      "    accuracy                           0.20       979\n",
      "   macro avg       0.12      0.10      0.09       979\n",
      "weighted avg       0.17      0.20      0.15       979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achintya/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_feature(Y, Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.01      0.02      0.02       102\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.80      0.26      0.39        31\n",
      "           4       0.00      0.00      0.00        42\n",
      "           5       0.37      0.16      0.22       100\n",
      "           6       0.00      0.00      0.00        20\n",
      "           7       0.00      0.00      0.00         5\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.23      0.62      0.34       101\n",
      "          10       0.00      0.00      0.00        20\n",
      "          11       0.00      0.00      0.00        28\n",
      "          12       0.24      0.64      0.34       100\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.22      0.14      0.17       100\n",
      "          15       0.00      0.00      0.00        20\n",
      "          16       0.24      0.20      0.22       102\n",
      "          17       0.00      0.00      0.00        20\n",
      "          18       0.00      0.00      0.00        13\n",
      "          19       0.05      0.04      0.05       100\n",
      "          20       0.40      0.10      0.16        20\n",
      "\n",
      "    accuracy                           0.20       979\n",
      "   macro avg       0.12      0.10      0.09       979\n",
      "weighted avg       0.17      0.20      0.15       979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achintya/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/achintya/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_feature(Y, Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.83      0.57        12\n",
      "           1       0.66      0.58      0.61       102\n",
      "           2       0.73      0.80      0.76        20\n",
      "           3       0.47      0.71      0.56        31\n",
      "           4       0.48      0.57      0.52        42\n",
      "           5       0.58      0.90      0.70       100\n",
      "           6       0.00      0.00      0.00        20\n",
      "           7       0.50      1.00      0.67         5\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       0.32      0.76      0.46       101\n",
      "          10       0.00      0.00      0.00        20\n",
      "          11       0.08      0.04      0.05        28\n",
      "          12       0.74      0.75      0.75       100\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.63      0.22      0.33       100\n",
      "          15       0.00      0.00      0.00        20\n",
      "          16       0.36      0.23      0.28       102\n",
      "          17       0.00      0.00      0.00        20\n",
      "          18       0.28      0.38      0.32        13\n",
      "          19       0.67      0.74      0.70       100\n",
      "          20       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.52       979\n",
      "   macro avg       0.38      0.45      0.39       979\n",
      "weighted avg       0.47      0.52      0.47       979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achintya/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/achintya/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_feature(Y, Y_fourier,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist([np.argmax(y) for y in Y_train], label = 'Train set', alpha = 0.5, bins = 21)\n",
    "plt.hist([np.argmax(y) for y in Y_test], label = 'Test set', alpha = 0.5, bins = 21)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining single task model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.layers import Input,Conv1D, Dense, MaxPooling1D, GlobalMaxPooling1D, Flatten\n",
    "from tensorflow.compat.v1.keras.models import Model\n",
    "from tensorflow.compat.v1.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inn = Input(shape = (X_train.shape[1], X_train.shape[2], ))\n",
    "\n",
    "x = Conv1D(16, 5, activation='relu', kernel_initializer=my_init)(inn)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(32, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(64, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "out = Dense(Y_test.shape[1], activation = 'softmax', kernel_initializer=my_init)(x)\n",
    "\n",
    "model = Model(inputs=[inn], outputs=[out])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics = ['accuracy'], optimizer = Adam(clipnorm = 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 9318, 3)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 9314, 16)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1862, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1858, 32)          2592      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 371, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 367, 64)           10304     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 21)                1365      \n",
      "=================================================================\n",
      "Total params: 14,517\n",
      "Trainable params: 14,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 734 samples, validate on 245 samples\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - 7s 9ms/sample - loss: 6.0218 - accuracy: 0.0872 - val_loss: 2.9763 - val_accuracy: 0.2163\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 2.7682 - accuracy: 0.1826 - val_loss: 2.4068 - val_accuracy: 0.2776\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 2.3308 - accuracy: 0.2875 - val_loss: 2.1839 - val_accuracy: 0.3388\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 2.0409 - accuracy: 0.4087 - val_loss: 1.8936 - val_accuracy: 0.4898\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.7889 - accuracy: 0.5327 - val_loss: 1.6652 - val_accuracy: 0.5592\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.5679 - accuracy: 0.5858 - val_loss: 1.4948 - val_accuracy: 0.6204\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.3654 - accuracy: 0.6117 - val_loss: 1.3412 - val_accuracy: 0.6245\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.1847 - accuracy: 0.6376 - val_loss: 1.2229 - val_accuracy: 0.6286\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.0376 - accuracy: 0.6526 - val_loss: 1.1281 - val_accuracy: 0.6367\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 0.9159 - accuracy: 0.6880 - val_loss: 1.0515 - val_accuracy: 0.6449\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    X_train, Y_train, \n",
    "    epochs = 10, \n",
    "    batch_size=64, \n",
    "    validation_data= (X_test, Y_test), \n",
    "    verbose=True, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.83      0.51        23\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       1.00      1.00      1.00        11\n",
      "           4       0.50      0.30      0.37        10\n",
      "           5       0.78      0.96      0.86        26\n",
      "           6       0.00      0.00      0.00         5\n",
      "           9       0.76      0.81      0.78        31\n",
      "          10       1.00      0.25      0.40         4\n",
      "          11       1.00      0.18      0.31        11\n",
      "          12       0.70      1.00      0.82        23\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.68      0.87      0.76        30\n",
      "          15       0.33      0.50      0.40         2\n",
      "          16       0.57      0.65      0.60        20\n",
      "          17       1.00      0.25      0.40         4\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.75      0.23      0.35        26\n",
      "          20       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.64       245\n",
      "   macro avg       0.58      0.46      0.45       245\n",
      "weighted avg       0.65      0.64      0.60       245\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achintya/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([np.argmax(x) for x in Y_test], [np.argmax(x) for x in model.predict(X_test)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask model + std as auxiliary loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inn = Input(shape =(X_train.shape[1], X_train.shape[2], ))\n",
    "\n",
    "x = Conv1D(16, 5, activation='relu', kernel_initializer=my_init)(inn)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(32, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(64, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "out = Dense(Y_test.shape[1], activation = 'softmax', name = 'classification', kernel_initializer=my_init)(x)\n",
    "out2 = Dense(1, activation = 'linear', name = 'regression', kernel_initializer=my_init)(x)\n",
    "\n",
    "model = Model(inputs=[inn], outputs=[out, out2])\n",
    "\n",
    "model.compile(loss=['categorical_crossentropy', 'mse'],\n",
    "              metrics = {'classification': 'accuracy'}, optimizer = Adam(clipnorm = 1.), loss_weights = [1, 1e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 734 samples, validate on 245 samples\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - 6s 8ms/sample - loss: 11.5075 - classification_loss: 10.8308 - regression_loss: 404.2150 - classification_accuracy: 0.0940 - val_loss: 4.7040 - val_classification_loss: 4.4910 - val_regression_loss: 215.0918 - val_classification_accuracy: 0.1265\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 4.1198 - classification_loss: 3.9402 - regression_loss: 131.1044 - classification_accuracy: 0.1335 - val_loss: 3.1053 - val_classification_loss: 3.0599 - val_regression_loss: 56.8965 - val_classification_accuracy: 0.1755\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 2.9002 - classification_loss: 2.8446 - regression_loss: 31.9341 - classification_accuracy: 0.1771 - val_loss: 2.5227 - val_classification_loss: 2.4974 - val_regression_loss: 28.1635 - val_classification_accuracy: 0.2367\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 2.4505 - classification_loss: 2.4101 - regression_loss: 20.5695 - classification_accuracy: 0.2411 - val_loss: 2.3572 - val_classification_loss: 2.3389 - val_regression_loss: 18.5825 - val_classification_accuracy: 0.2408\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 2.2664 - classification_loss: 2.2372 - regression_loss: 14.6847 - classification_accuracy: 0.2875 - val_loss: 2.1738 - val_classification_loss: 2.1604 - val_regression_loss: 14.4787 - val_classification_accuracy: 0.3020\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 2.0591 - classification_loss: 2.0329 - regression_loss: 11.4480 - classification_accuracy: 0.3815 - val_loss: 2.0035 - val_classification_loss: 1.9935 - val_regression_loss: 10.9352 - val_classification_accuracy: 0.3673\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.8803 - classification_loss: 1.8607 - regression_loss: 9.1438 - classification_accuracy: 0.4210 - val_loss: 1.8594 - val_classification_loss: 1.8533 - val_regression_loss: 8.5217 - val_classification_accuracy: 0.3592\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.7102 - classification_loss: 1.6900 - regression_loss: 7.8855 - classification_accuracy: 0.4564 - val_loss: 1.6971 - val_classification_loss: 1.6915 - val_regression_loss: 7.8197 - val_classification_accuracy: 0.4245\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.5340 - classification_loss: 1.5141 - regression_loss: 7.1417 - classification_accuracy: 0.5204 - val_loss: 1.5207 - val_classification_loss: 1.5144 - val_regression_loss: 7.1275 - val_classification_accuracy: 0.5265\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.3571 - classification_loss: 1.3370 - regression_loss: 6.8720 - classification_accuracy: 0.5463 - val_loss: 1.4041 - val_classification_loss: 1.3981 - val_regression_loss: 6.7140 - val_classification_accuracy: 0.5224\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    X_train, [Y_train, Y_train_std],\n",
    "    epochs = 10,\n",
    "    batch_size = 64,\n",
    "    validation_data = (X_test, [Y_test, Y_test_std]),\n",
    "    verbose = True,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.43      0.39        23\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.64      0.64      0.64        11\n",
      "           4       0.50      0.30      0.37        10\n",
      "           5       0.72      0.50      0.59        26\n",
      "           6       0.25      0.20      0.22         5\n",
      "           9       0.71      0.81      0.76        31\n",
      "          10       1.00      0.50      0.67         4\n",
      "          11       0.29      0.18      0.22        11\n",
      "          12       0.54      0.87      0.67        23\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.62      0.60      0.61        30\n",
      "          15       0.67      1.00      0.80         2\n",
      "          16       0.48      0.80      0.60        20\n",
      "          17       0.00      0.00      0.00         4\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.27      0.31      0.29        26\n",
      "          20       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.52       245\n",
      "   macro avg       0.45      0.41      0.40       245\n",
      "weighted avg       0.50      0.52      0.49       245\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achintya/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([np.argmax(x) for x in Y_test], \n",
    "                            [np.argmax(x) for x in model.predict(X_test)[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask Model + Foureir coefs as auxiliary loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inn = Input(shape = (X_train.shape[1], X_train.shape[2], ))\n",
    "\n",
    "x = Conv1D(16, 5, activation='relu', kernel_initializer=my_init)(inn)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(32, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(64, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "out = Dense(Y_test.shape[1], activation = 'softmax', name = 'classification', kernel_initializer=my_init)(x)\n",
    "out2 = Dense(Y_train_fourier.shape[1], activation = 'linear', name = 'regression', kernel_initializer=my_init)(x)\n",
    "\n",
    "model = Model(inputs=[inn], outputs=[out, out2])\n",
    "\n",
    "model.compile(loss=['categorical_crossentropy', 'mse'],\n",
    "              metrics = {'classification': 'accuracy'}, optimizer = Adam(clipnorm = 1.), loss_weights = [1, 1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 734 samples, validate on 245 samples\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - 10s 14ms/sample - loss: 5.0036 - classification_loss: 4.7998 - regression_loss: 9.9058 - classification_accuracy: 0.1144 - val_loss: 2.8130 - val_classification_loss: 2.7753 - val_regression_loss: 3.3973 - val_classification_accuracy: 0.1918\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 2.4649 - classification_loss: 2.4390 - regression_loss: 2.2601 - classification_accuracy: 0.2520 - val_loss: 2.2036 - val_classification_loss: 2.1925 - val_regression_loss: 1.2921 - val_classification_accuracy: 0.2939\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 2.0263 - classification_loss: 2.0064 - regression_loss: 1.2013 - classification_accuracy: 0.3828 - val_loss: 1.9051 - val_classification_loss: 1.8957 - val_regression_loss: 1.0929 - val_classification_accuracy: 0.4286\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.7098 - classification_loss: 1.6888 - regression_loss: 1.1609 - classification_accuracy: 0.4986 - val_loss: 1.6276 - val_classification_loss: 1.6176 - val_regression_loss: 1.2660 - val_classification_accuracy: 0.5184\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.4592 - classification_loss: 1.4375 - regression_loss: 1.3305 - classification_accuracy: 0.5627 - val_loss: 1.4528 - val_classification_loss: 1.4404 - val_regression_loss: 1.4131 - val_classification_accuracy: 0.5306\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.2761 - classification_loss: 1.2540 - regression_loss: 1.4164 - classification_accuracy: 0.5913 - val_loss: 1.3029 - val_classification_loss: 1.2899 - val_regression_loss: 1.4965 - val_classification_accuracy: 0.5796\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 1.1196 - classification_loss: 1.0958 - regression_loss: 1.4712 - classification_accuracy: 0.6390 - val_loss: 1.1679 - val_classification_loss: 1.1556 - val_regression_loss: 1.5080 - val_classification_accuracy: 0.5959\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 0.9955 - classification_loss: 0.9714 - regression_loss: 1.4589 - classification_accuracy: 0.6744 - val_loss: 1.0835 - val_classification_loss: 1.0707 - val_regression_loss: 1.4657 - val_classification_accuracy: 0.6204\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 0.8982 - classification_loss: 0.8750 - regression_loss: 1.3907 - classification_accuracy: 0.7030 - val_loss: 1.0215 - val_classification_loss: 1.0092 - val_regression_loss: 1.3761 - val_classification_accuracy: 0.6327\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - 5s 7ms/sample - loss: 0.8199 - classification_loss: 0.7978 - regression_loss: 1.3126 - classification_accuracy: 0.7207 - val_loss: 0.9791 - val_classification_loss: 0.9670 - val_regression_loss: 1.2876 - val_classification_accuracy: 0.6327\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    X_train, [Y_train, Y_train_fourier],\n",
    "    epochs = 10,\n",
    "    batch_size = 64,\n",
    "    validation_data = (X_test, [Y_test, Y_test_fourier]),\n",
    "    verbose = True,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.78      0.46        23\n",
      "           2       1.00      0.14      0.25         7\n",
      "           3       1.00      0.82      0.90        11\n",
      "           4       0.33      0.10      0.15        10\n",
      "           5       0.78      0.96      0.86        26\n",
      "           6       0.00      0.00      0.00         5\n",
      "           9       0.92      0.74      0.82        31\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       0.50      0.36      0.42        11\n",
      "          12       0.77      1.00      0.87        23\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.83      0.80      0.81        30\n",
      "          15       0.40      1.00      0.57         2\n",
      "          16       0.55      0.85      0.67        20\n",
      "          17       0.00      0.00      0.00         4\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00        26\n",
      "          20       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.63       245\n",
      "   macro avg       0.52      0.52      0.48       245\n",
      "weighted avg       0.60      0.63      0.59       245\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achintya/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        [np.argmax(x) for x in Y_test], \n",
    "        [np.argmax(x) for x in model.predict(X_test)[0]]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
